[
  {
    "objectID": "logistic_regression.html",
    "href": "logistic_regression.html",
    "title": "PCA-Based Policy Indices",
    "section": "",
    "text": "This analysis investigates the relationship between gun policies and firearm mortality rates across U.S. states. Prior research suggests that certain policy approaches may be associated with lower rates of gun violence, but there has been limited work using data-driven approaches to identify which policy domains have the strongest protective associations.\nIn this study, we use Principal Component Analysis (PCA) to identify natural groupings of gun policies and then apply logistic regression to assess how these policy domains relate to firearm mortality outcomes. This approach allows us to move beyond subjective policy groupings to statistical categorizations that better reflect how these policies cluster in practice."
  },
  {
    "objectID": "logistic_regression.html#introduction",
    "href": "logistic_regression.html#introduction",
    "title": "PCA-Based Policy Indices",
    "section": "",
    "text": "This analysis investigates the relationship between gun policies and firearm mortality rates across U.S. states. Prior research suggests that certain policy approaches may be associated with lower rates of gun violence, but there has been limited work using data-driven approaches to identify which policy domains have the strongest protective associations.\nIn this study, we use Principal Component Analysis (PCA) to identify natural groupings of gun policies and then apply logistic regression to assess how these policy domains relate to firearm mortality outcomes. This approach allows us to move beyond subjective policy groupings to statistical categorizations that better reflect how these policies cluster in practice."
  },
  {
    "objectID": "logistic_regression.html#data-preparation",
    "href": "logistic_regression.html#data-preparation",
    "title": "PCA-Based Policy Indices",
    "section": "2 Data Preparation",
    "text": "2 Data Preparation\nWe begin by loading the dataset containing state-level information on firearm mortality rates and various gun policy indicators. We then create a binary outcome variable representing whether a state’s firearm mortality rate is above or below the median.\n\n\nCode\n# Load necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, \n                            f1_score, roc_curve, auc, confusion_matrix, \n                            classification_report)\n\n# Set plotting style\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette(\"colorblind\")\nplt.rcParams.update({'font.size': 8})  # Reduce font size globally\n\n# Load the dataset\ndf = pd.read_csv(\"data/merged_data.csv\")\n\n# Create a binary target variable for firearm mortality\ndf[\"firearm_mortality_above_median\"] = (\n    df[\"firearm_mortality_by_state_2022\"] &gt; \n    df[\"firearm_mortality_by_state_2022\"].median()\n).astype(int)\n\n# Display basic dataset information\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Number of states with high firearm mortality: {df['firearm_mortality_above_median'].sum()}\")\nprint(f\"Number of states with low firearm mortality: {len(df) - df['firearm_mortality_above_median'].sum()}\")\n\n\nDataset shape: (51, 63)\nNumber of states with high firearm mortality: 25\nNumber of states with low firearm mortality: 26\n\n\nBased on a prior Principal Component Analysis, we identified six natural groupings of gun policies. These groupings better reflect the statistical relationships among policies than arbitrary categorizations.\n\n\nCode\n# Define PCA-based composite indices\npca_based_indices = {\n    # Group 1: Weapon and Purchase Restrictions\n    'weapon_purchase_restrictions_index': [\n        'high_capacity_magazines_prohibited',\n        'asault_weapons_prohibited', \n        'background_check_or_purchase_permit',\n        'dealer_lisence_required',\n        'waiting_period',\n        'age_requirement'\n    ],\n    \n    # Group 2: Risk-Based Intervention\n    'risk_intervention_index': [\n        'red_flag_laws',\n        'extreme_risk_law',\n        'gun_removal_program',\n        'rejected_shoot_first_laws'\n    ],\n    \n    # Group 3: Domestic Violence Prevention\n    'domestic_violence_prevention_index': [\n        'prohibition_for_stalkers',\n        'prohibition_for_domestic_abusers',\n        'prohibition_for_convicted_domestic_abusers',\n        'abusers_turn_in_gun_after_conviction',\n        'restraining_order_prohibitor'\n    ],\n    \n    # Group 4: High-Risk Individual Prohibitions\n    'high_risk_individual_index': [\n        'felony_prohibitor',\n        'fugitive_from_justice_prohibitor',\n        'mentaI_illness_prohibitor',\n        'hate_crime_prohibitor',\n        'no_purchase_after_violent_offense',\n        'mental_health_in_background_check'\n    ],\n    \n    # Group 5: Location-Based Restrictions\n    'location_restrictions_index': [\n        'no_open_carry',\n        'concealed_carry_permit_required',\n        'no_guns_in_k_through_twelve_schools',\n        'no_guns_at_demonstrations',\n        'no_guns_on_college_campuses',\n        'bar_concealed_carry_by_people_with_violent_misdemeanors'\n    ],\n    \n    # Group 6: Safety Regulations\n    'safety_regulations_index': [\n        'secure_storage_child_access_laws',\n        'funding_for_violence_intervention'\n    ]\n}\n\n# Function to create composite indices\ndef create_composite_indices(df, index_definitions):\n    df_copy = df.copy()\n    \n    for name, columns in index_definitions.items():\n        df_copy[name] = df_copy[columns].fillna(0).mean(axis=1)\n    \n    return df_copy\n\n# Create dataset with PCA-based indices\ndf_with_indices = create_composite_indices(df, pca_based_indices)\n\n# Display summary statistics for each index\nindex_summary = df_with_indices[list(pca_based_indices.keys())].describe()\nprint(\"Summary Statistics for Policy Indices:\")\nindex_summary\n\n\nSummary Statistics for Policy Indices:\n\n\n\n\n\n\n\n\n\nweapon_purchase_restrictions_index\nrisk_intervention_index\ndomestic_violence_prevention_index\nhigh_risk_individual_index\nlocation_restrictions_index\nsafety_regulations_index\n\n\n\n\ncount\n51.000000\n51.000000\n51.000000\n51.000000\n51.000000\n51.000000\n\n\nmean\n0.313725\n0.343137\n0.458824\n0.562092\n0.500000\n0.656863\n\n\nstd\n0.370656\n0.396739\n0.353936\n0.282766\n0.316228\n0.367290\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.200000\n0.333333\n0.333333\n0.500000\n\n\n50%\n0.166667\n0.000000\n0.400000\n0.666667\n0.500000\n0.500000\n\n\n75%\n0.583333\n0.750000\n0.800000\n0.666667\n0.666667\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000"
  },
  {
    "objectID": "logistic_regression.html#understanding-the-policy-domains",
    "href": "logistic_regression.html#understanding-the-policy-domains",
    "title": "PCA-Based Policy Indices",
    "section": "3 Understanding the Policy Domains",
    "text": "3 Understanding the Policy Domains\nThe six policy domains identified through PCA represent different approaches to gun policy:\n\nWeapon and Purchase Restrictions: Policies that control who can purchase firearms and what types of weapons are available (background checks, waiting periods, magazine limits).\nRisk-Based Intervention: Policies that provide mechanisms to temporarily remove firearms from individuals who pose a risk to themselves or others (red flag laws, extreme risk protection orders).\nDomestic Violence Prevention: Policies specifically targeting the intersection of domestic violence and firearms (prohibitions for stalkers, abusers).\nHigh-Risk Individual Prohibitions: Policies that prevent firearm access for categories of individuals deemed high-risk (felons, fugitives, those with mental illness).\nLocation-Based Restrictions: Policies that restrict where firearms can be carried (schools, demonstrations, open carry restrictions).\nSafety Regulations: Policies focused on safe storage and violence prevention programs.\n\nLet’s visualize the distribution of these indices across states:\n\n\nCode\n# Visualize the distribution of each policy index with smaller size\nfig, axes = plt.subplots(3, 2, figsize=(4, 3))  # Very compact size\naxes = axes.flatten()\n\nfor i, index_name in enumerate(pca_based_indices.keys()):\n    sns.histplot(df_with_indices[index_name], ax=axes[i], kde=True, \n                 bins=6, line_kws={'linewidth': 1})  # Fewer bins, thinner lines\n    \n    # Smaller title and labels\n    axes[i].set_title(index_name.replace('_index', '').replace('_', ' ').title(), fontsize=6)\n    axes[i].set_xlabel(\"\", fontsize=5)  # Remove x-label text\n    axes[i].set_ylabel(\"\", fontsize=5)  # Remove y-label text\n    \n    # Smaller tick labels and fewer ticks\n    axes[i].tick_params(axis='both', which='major', labelsize=5)\n    axes[i].set_yticks([])  # Remove y-ticks entirely\n\n# Extremely tight spacing\nplt.subplots_adjust(left=0.05, right=0.95, bottom=0.05, top=0.90, wspace=0.2, hspace=0.2)\nplt.tight_layout(pad=0.1, w_pad=0.1, h_pad=0.1)\nplt.suptitle(\"Distribution of Policy Indices\", fontsize=4, y=0.98)\nplt.show()"
  },
  {
    "objectID": "logistic_regression.html#correlations-between-policy-domains",
    "href": "logistic_regression.html#correlations-between-policy-domains",
    "title": "PCA-Based Policy Indices",
    "section": "4 Correlations Between Policy Domains",
    "text": "4 Correlations Between Policy Domains\nBefore building our predictive model, let’s examine how these policy domains correlate with each other and with firearm mortality rates:\n\n\nCode\n# Calculate correlation matrix\ncorrelation_vars = list(pca_based_indices.keys()) + ['firearm_mortality_by_state_2022']\ncorrelation_matrix = df_with_indices[correlation_vars].corr()\n\n# Plot correlation heatmap with minimal size\nplt.figure(figsize=(4, 3.5))\nmask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\nsns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', \n            fmt=\".2f\", linewidths=0.2, vmin=-1, vmax=1, annot_kws={\"size\": 5})\nplt.title('Correlation Matrix', fontsize=8)\nplt.xticks(fontsize=5, rotation=45)\nplt.yticks(fontsize=5)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "logistic_regression.html#logistic-regression-modeling",
    "href": "logistic_regression.html#logistic-regression-modeling",
    "title": "PCA-Based Policy Indices",
    "section": "5 Logistic Regression Modeling",
    "text": "5 Logistic Regression Modeling\nWe’ll build a logistic regression model to predict whether a state has above-median firearm mortality based on its policy index values. We’ll compare three types of logistic regression: standard (no regularization), Lasso (L1 regularization), and Ridge (L2 regularization).\n\n5.1 Data Preparation for Modeling\n\n\nCode\n# Prepare data for logistic regression\nfeature_names = list(pca_based_indices.keys())\nX = df_with_indices[feature_names].copy()\ny = df_with_indices['firearm_mortality_above_median']\n\n# Handle missing values\nimputer = SimpleImputer(strategy=\"mean\")\nX_imputed = imputer.fit_transform(X)\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_imputed)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n)\n\n\n\n\n5.2 Model Comparison with Cross-Validation\n\n\nCode\n# Compare different logistic regression models\nmodels = {\n    \"Standard\": LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=1000, random_state=42),\n    \"Lasso (L1)\": LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=1000, random_state=42),\n    \"Ridge (L2)\": LogisticRegression(penalty=\"l2\", solver=\"liblinear\", max_iter=1000, random_state=42)\n}\n\n# Evaluate models with cross-validation\nprint(\"Cross-Validation Results:\")\ncv_results = {}\nfor name, model in models.items():\n    # Perform cross-validation\n    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"accuracy\")\n    cv_results[name] = {\n        \"Mean Accuracy\": np.mean(cv_scores),\n        \"Std Dev\": np.std(cv_scores)\n    }\n    print(f\"{name}: Accuracy = {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n\n# Visualize cross-validation results - much more compact\nplt.figure(figsize=(4, 2.5))\nmodels_names = list(cv_results.keys())\naccuracies = [cv_results[name][\"Mean Accuracy\"] for name in models_names]\nstd_devs = [cv_results[name][\"Std Dev\"] for name in models_names]\n\nplt.bar(models_names, accuracies, yerr=std_devs, capsize=3, alpha=0.7)\nplt.ylabel('CV Accuracy', fontsize=7)\nplt.title('Model Comparison', fontsize=8)\nplt.ylim(0.7, 1.0)  # Adjusted to zoom in on relevant range\nplt.grid(axis='y', linestyle='--', alpha=0.3)\nplt.xticks(fontsize=6)\nplt.yticks(fontsize=6)\nplt.tight_layout()\nplt.show()\n\n\nCross-Validation Results:\nStandard: Accuracy = 0.7618 (±0.1376)\nLasso (L1): Accuracy = 0.7818 (±0.1002)\nRidge (L2): Accuracy = 0.7618 (±0.1045)\n\n\n\n\n\n\n\n\n\nBased on the cross-validation results, Lasso (L1) Logistic Regression performs best. We’ll use this model for our final evaluation.\n\n\n5.3 Final Model Training and Evaluation\n\n\nCode\n# Use the best model (based on CV results) for final fitting\nbest_model = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=1000, random_state=42)\nbest_model.fit(X_train, y_train)\n\n# Make predictions\ny_pred = best_model.predict(X_test)\ny_prob = best_model.predict_proba(X_test)[:, 1]\n\n# Calculate and display performance metrics\nprint(\"\\nTest Set Performance:\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\nprint(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\nprint(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\nprint(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\nroc_auc = auc(*roc_curve(y_test, y_prob)[:2])\nprint(f\"ROC AUC: {roc_auc:.4f}\")\n\n# Print classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n\n\nTest Set Performance:\nAccuracy: 0.6364\nPrecision: 0.5714\nRecall: 0.8000\nF1 Score: 0.6667\nROC AUC: 0.8667\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.75      0.50      0.60         6\n           1       0.57      0.80      0.67         5\n\n    accuracy                           0.64        11\n   macro avg       0.66      0.65      0.63        11\nweighted avg       0.67      0.64      0.63        11\n\n\n\n\n\n5.4 Model Performance Visualization\n\nCode\n# Plot confusion matrix (much smaller)\nplt.figure(figsize=(3, 2.5))\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 10})\nplt.xlabel('Predicted', fontsize=7)\nplt.ylabel('True', fontsize=7)\nplt.title('Confusion Matrix', fontsize=8)\nplt.xticks(fontsize=6)\nplt.yticks(fontsize=6)\nplt.tight_layout()\nplt.show()\n\n# Plot ROC curve (much smaller)\nplt.figure(figsize=(3, 2.5))\nfpr, tpr, _ = roc_curve(y_test, y_prob)\nplt.plot(fpr, tpr, color='blue', lw=1.5, label=f'AUC = {roc_auc:.2f}')\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=0.5)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate', fontsize=7)\nplt.ylabel('True Positive Rate', fontsize=7)\nplt.title('ROC Curve', fontsize=8)\nplt.legend(loc=\"lower right\", fontsize=6)\nplt.grid(alpha=0.2)\nplt.xticks(fontsize=6)\nplt.yticks(fontsize=6)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "logistic_regression.html#feature-importance-analysis",
    "href": "logistic_regression.html#feature-importance-analysis",
    "title": "PCA-Based Policy Indices",
    "section": "6 Feature Importance Analysis",
    "text": "6 Feature Importance Analysis\nOne of the key advantages of using Lasso regression is that it helps identify the most important features by shrinking less important coefficients to zero. Let’s analyze which policy domains have the strongest associations with firearm mortality:\n\n\nCode\n# Feature importance analysis\ncoefficients = best_model.coef_[0]\nimportance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Coefficient': coefficients,\n    'Abs_Coefficient': np.abs(coefficients)\n}).sort_values('Abs_Coefficient', ascending=False)\n\n# Add interpretation column\nimportance_df['Effect'] = ['Increases Mortality Risk' if c &gt; 0 else 'Decreases Mortality Risk' \n                         for c in importance_df['Coefficient']]\n\nprint(\"\\nFeature Importance:\")\nprint(importance_df)\n\n\n\nFeature Importance:\n                              Feature  Coefficient  Abs_Coefficient  \\\n0  weapon_purchase_restrictions_index    -1.209084         1.209084   \n5            safety_regulations_index    -0.604965         0.604965   \n3          high_risk_individual_index    -0.367641         0.367641   \n4         location_restrictions_index     0.169691         0.169691   \n1             risk_intervention_index     0.000000         0.000000   \n2  domestic_violence_prevention_index     0.000000         0.000000   \n\n                     Effect  \n0  Decreases Mortality Risk  \n5  Decreases Mortality Risk  \n3  Decreases Mortality Risk  \n4  Increases Mortality Risk  \n1  Decreases Mortality Risk  \n2  Decreases Mortality Risk  \n\n\n\n\nCode\n# Create a mapping for cleaner feature names\nclean_names = {\n    'domestic_violence_prevention_index': 'Domestic Violence Prevention',\n    'risk_intervention_index': 'Risk Intervention',\n    'location_restrictions_index': 'Location Restrictions',\n    'high_risk_individual_index': 'High-Risk Individual',\n    'safety_regulations_index': 'Safety Regulations',\n    'weapon_purchase_restrictions_index': 'Weapon Purchase Restrictions'\n}\n\n# Apply mapping to DataFrame\nimportance_df['Clean Feature'] = importance_df['Feature'].map(clean_names)\n\n# Sort by coefficient value for better visualization\nimportance_df = importance_df.sort_values('Coefficient')\n\n# Set colors\ncolors = ['red' if coef &gt; 0 else 'green' for coef in importance_df['Coefficient']]\n\n# Plot - much more compact\nplt.figure(figsize=(5, 3))\nplt.barh(\n    importance_df['Clean Feature'],\n    importance_df['Coefficient'],\n    color=colors,\n    edgecolor='black',\n    height=0.5  # Thinner bars\n)\n\n# Simplified aesthetics\nplt.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\nplt.xlabel('Effect on Log-Odds', fontsize=7)\nplt.title('Policy Impact on Firearm Mortality', fontsize=8)\nplt.grid(axis='x', linestyle='--', alpha=0.3)\nplt.xticks(fontsize=6)\nplt.yticks(fontsize=6)\n\n# Add a small legend instead of caption\nplt.legend([plt.Rectangle((0,0),1,1, color='green'), \n            plt.Rectangle((0,0),1,1, color='red')],\n           ['Lower mortality', 'Higher mortality'], \n           fontsize=6, loc='lower right')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "logistic_regression.html#discussion-and-interpretation",
    "href": "logistic_regression.html#discussion-and-interpretation",
    "title": "PCA-Based Policy Indices",
    "section": "7 Discussion and Interpretation",
    "text": "7 Discussion and Interpretation\nOur analysis reveals several key findings about the relationship between gun policies and firearm mortality:\n\nWeapon Purchase Restrictions: This domain shows the strongest protective association with firearm mortality. States with more comprehensive purchase restrictions (including background checks, waiting periods, dealer licensing, and assault weapon bans) tend to have significantly lower firearm mortality rates.\nSafety Regulations: The second most important factor, also showing a substantial protective effect. This includes secure storage laws and funding for violence intervention programs.\nHigh-Risk Individual Prohibitions: These policies also show a moderate protective association, suggesting that limiting gun access for high-risk individuals (such as those with felony convictions or mental illness) may help reduce mortality.\nLocation Restrictions: Interestingly, this is the only domain with a positive coefficient, suggesting that location-based restrictions might be associated with slightly higher mortality rates. This could reflect that these policies might be reactive (implemented in response to existing violence) rather than preventive.\nRisk Intervention and Domestic Violence Prevention: These domains were eliminated by the Lasso regression (coefficients set to zero), suggesting that after accounting for the other policy domains, they don’t add significant predictive power. This doesn’t necessarily mean these policies are ineffective, but rather that their effects might already be captured by the other indices.\n\nThe model shows good discrimination ability with an AUC of 0.87, suggesting that these policy domains together provide meaningful predictive power for firearm mortality outcomes."
  },
  {
    "objectID": "logistic_regression.html#limitations",
    "href": "logistic_regression.html#limitations",
    "title": "PCA-Based Policy Indices",
    "section": "8 Limitations",
    "text": "8 Limitations\nSeveral limitations should be considered when interpreting these results:\n\nCausality: This analysis identifies associations but cannot establish causality. States with lower firearm mortality might be more likely to implement certain policies, rather than the policies causing the lower mortality.\nSmall Sample Size: With only 50 states (plus DC), the statistical power is limited, especially for the test set evaluation.\nImplementation Quality: Our indices measure the presence of policies but not how well they are implemented or enforced.\nConfounding Factors: Many other factors beyond gun policies influence firearm mortality, including socioeconomic conditions, healthcare access, and cultural factors."
  },
  {
    "objectID": "logistic_regression.html#conclusion",
    "href": "logistic_regression.html#conclusion",
    "title": "PCA-Based Policy Indices",
    "section": "9 Conclusion",
    "text": "9 Conclusion\nThis data-driven analysis suggests that comprehensive weapon purchase restrictions may be the most promising policy approach for reducing firearm mortality, followed by safety regulations and high-risk individual prohibitions. Future research should examine the causal mechanisms behind these associations and how policy implementation affects outcomes.\nThe use of PCA-based policy groupings provides a novel approach to understanding how gun policies naturally cluster and relate to mortality outcomes, moving beyond subjective categorizations to data-driven insights."
  },
  {
    "objectID": "llm.html",
    "href": "llm.html",
    "title": "LLM Usage Log",
    "section": "",
    "text": "Throughout the development of this firearm mortality analysis project, we utilized large language models as a supplementary tool. This brief log documents how LLMs were incorporated while maintaining the educational value and originality of the work.\n\nHow LLMs Were Used\n\nCode assistance: Helped troubleshoot errors and suggest syntax improvements for statistical analyses\nVisualization enhancements: Provided ideas for clearer data visualizations\nInterpretation suggestions: Offered alternative ways to interpret statistical findings\nDocument organization: Assisted with structuring the Quarto documents\n\n\n\nLearning Process\nWhile LLMs provided technical assistance, they functionally served as an interactive reference rather than replacing the learning process. Throughout this project:\n\nWe developed a deeper understanding of regression techniques and their applications\nWe made all key analytical decisions and interpretations based on my understanding of the data\nWe critically evaluated LLM suggestions rather than implementing them without consideration\nThe conceptualization of the project and research questions remained entirely our own\n\n\n\nAdded Value Without Replacing Creativity\nThe use of LLMs enhanced the project’s execution without diminishing its educational or creative aspects."
  },
  {
    "objectID": "linear_regression.html",
    "href": "linear_regression.html",
    "title": "Understanding Firearm Mortality Through Principal Component Regression",
    "section": "",
    "text": "This analysis examines the relationship between socioeconomic, policy, and public health factors and firearm mortality rates across U.S. states. Firearm mortality represents a complex public health challenge that likely stems from multiple interacting factors rather than simple, direct causes. Using Principal Component Regression (PCR), we can reduce a complex set of 27 predictors into meaningful latent factors to understand what drives differences in firearm mortality.\n\n\nTraditional regression approaches face challenges when analyzing firearm mortality:\n\nMulticollinearity: Many potential predictors (like poverty, education, and crime) are strongly correlated with each other, making it difficult to isolate their individual effects.\nDimensionality: With 27 potential predictors and limited observations (50 states), we risk overfitting with standard regression approaches.\nLatent Patterns: The underlying drivers of firearm mortality may be broader societal patterns rather than individual variables.\n\nPrincipal Component Regression addresses these challenges by:\n\nFirst using Principal Component Analysis (PCA) to reduce our 27 predictors to uncorrelated components that capture underlying patterns\nThen using these components as predictors in a regression model of firearm mortality\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\n# Set visualization style for consistency\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (8, 4)\nplt.rcParams['font.size'] = 10"
  },
  {
    "objectID": "linear_regression.html#introduction",
    "href": "linear_regression.html#introduction",
    "title": "Understanding Firearm Mortality Through Principal Component Regression",
    "section": "",
    "text": "This analysis examines the relationship between socioeconomic, policy, and public health factors and firearm mortality rates across U.S. states. Firearm mortality represents a complex public health challenge that likely stems from multiple interacting factors rather than simple, direct causes. Using Principal Component Regression (PCR), we can reduce a complex set of 27 predictors into meaningful latent factors to understand what drives differences in firearm mortality.\n\n\nTraditional regression approaches face challenges when analyzing firearm mortality:\n\nMulticollinearity: Many potential predictors (like poverty, education, and crime) are strongly correlated with each other, making it difficult to isolate their individual effects.\nDimensionality: With 27 potential predictors and limited observations (50 states), we risk overfitting with standard regression approaches.\nLatent Patterns: The underlying drivers of firearm mortality may be broader societal patterns rather than individual variables.\n\nPrincipal Component Regression addresses these challenges by:\n\nFirst using Principal Component Analysis (PCA) to reduce our 27 predictors to uncorrelated components that capture underlying patterns\nThen using these components as predictors in a regression model of firearm mortality\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\n# Set visualization style for consistency\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (8, 4)\nplt.rcParams['font.size'] = 10"
  },
  {
    "objectID": "linear_regression.html#data-preprocessing",
    "href": "linear_regression.html#data-preprocessing",
    "title": "Understanding Firearm Mortality Through Principal Component Regression",
    "section": "Data & Preprocessing",
    "text": "Data & Preprocessing\nOur dataset contains state-level information on 27 potential predictors of firearm mortality, including socioeconomic indicators, crime rates, gun policies, educational attainment, and health metrics.\n\n\nCode\n# Load data\nmerged_data = pd.read_csv(\"data/merged_data.csv\")\n\n# Define the variables of interest\nselected_columns = [\n    'State',\n    'gini_index',\n    'mental health_score',\n    'gun_policy_strength',\n    'alcohol_related_death_rate',\n    'drug_overdose_mortality_rate',\n    'dv_people_to_shelter',\n    'dv_spending_per_person',\n    'unemployment_rate',\n    'labor_participation_women_percentage',\n    'domestic_violence_percentage',\n    'gun_ownership_rates_per_state',\n    'CrimeViolentRate',\n    'CrimeNonViolentRate',\n    'IncarcerationRate_Per100kResidents_2022',\n    'IncarcerationRate_BlackWhiteDisparity(X_to_1)_2020',\n    'IncarcerationRate_YouthCustodyRatePer100kYouths_2021',\n    'teen_birth_rate',\n    'less_than_hs_diploma_women',\n    'HS_Diploma_or_Equivalent_Only_women',\n    'Some_College/Associates_Degree_women',\n    \"Bachelor's_Degree/Higher_women\",\n    '2022 Suicide Deaths per 100,000 people (age-adjusted)',\n    'poverty_rate_2023',\n]\n\n# Define target variable\ntarget = 'firearm_mortality_by_state_2022'\n\n# Create modeling dataset\nmodel_data = merged_data[selected_columns + [target]]\n\n# Data preprocessing\n# Create feature matrix\nX = model_data.drop(columns=['State', target])\n\n# Clean data - replace commas and convert to numeric\nX = X.apply(lambda col: col.str.replace(',', '') if col.dtype == 'object' else col)\nX = X.apply(pd.to_numeric, errors='coerce')\n\n# Handle missing values\nmissing_count = X.isna().sum().sum()\nif missing_count &gt; 0:\n    print(f\"Handling {missing_count} missing values with mean imputation\")\n    X = X.fillna(X.mean())\n\n# Extract target variable\ny = model_data[target]\n\n# Standardize predictors (essential for PCA)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Print target summary statistics\nprint(\"\\nFirearm Mortality Rate Summary Statistics:\")\nprint(y.describe().round(2))\n\n\nHandling 8 missing values with mean imputation\n\nFirearm Mortality Rate Summary Statistics:\ncount    51.00\nmean     15.78\nstd       6.23\nmin       3.10\n25%      12.10\n50%      15.60\n75%      19.95\nmax      29.60\nName: firearm_mortality_by_state_2022, dtype: float64"
  },
  {
    "objectID": "linear_regression.html#principal-component-analysis-results",
    "href": "linear_regression.html#principal-component-analysis-results",
    "title": "Understanding Firearm Mortality Through Principal Component Regression",
    "section": "Principal Component Analysis Results",
    "text": "Principal Component Analysis Results\n\n1. Five Key Components Explain Most Variation\nOur analysis identifies five principal components that optimally predict firearm mortality rates, accounting for approximately 70% of the variance in the original predictors and achieving an R² of 0.816 in explaining firearm mortality rates.\n\n\nCode\n# Perform PCA\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# Visualize explained variance\nfig, ax = plt.subplots(1, 2, figsize=(8, 3))\n\n# Individual variance\nax[0].bar(range(1, 11), pca.explained_variance_ratio_[:10])\nax[0].set_xlabel('Principal Component')\nax[0].set_ylabel('Explained Variance Ratio')\nax[0].set_title('Variance Explained by Each Component')\nax[0].set_xticks(range(1, 11))\n\n# Cumulative variance\ncumulative = np.cumsum(pca.explained_variance_ratio_)\nax[1].plot(range(1, len(cumulative)+1), cumulative, marker='o')\nax[1].set_xlabel('Number of Components')\nax[1].set_ylabel('Cumulative Explained Variance')\nax[1].set_title('Cumulative Explained Variance')\nax[1].axhline(y=0.8, color='r', linestyle='--', label='80% Variance')\nax[1].axhline(y=0.9, color='g', linestyle='--', label='90% Variance')\nax[1].set_xticks(range(1, 11))\nax[1].legend()\n\nplt.subplots_adjust(left=0.1, right=0.95, bottom=0.2, top=0.85, wspace=0.3)\nplt.show()\n\n\n\n\n\nExplained variance by principal components\n\n\n\n\n\n\nConsistent Findings Across Methods\n\nGun Culture & Policy: Across all modeling approaches, variables related to gun ownership and policy consistently emerged as key contributors to firearm mortality.\nCrime and Incarceration: Violent crime rates and incarceration metrics emerged as significant factors across all models.\nSocioeconomic Context: Poverty rates and educational attainment consistently showed significant relationships with firearm mortality.\nGeographic Patterns: Regional clusters appeared consistently across analyses, with northeastern states showing lower firearm mortality rates and southern states showing higher rates."
  },
  {
    "objectID": "linear_regression.html#conclusions",
    "href": "linear_regression.html#conclusions",
    "title": "Understanding Firearm Mortality Through Principal Component Regression",
    "section": "Conclusions",
    "text": "Conclusions\nOur analysis reveals that firearm mortality across U.S. states is driven by complex, interrelated factors that can be understood through several key dimensions:\n\n1. Principal Components of Firearm Mortality\nThe five components identified through PCR represent coherent patterns in our society:\n\nGun Culture & Carceral Risk: The dominant predictor, characterized by high gun ownership, weaker gun policies, and elevated incarceration rates\nEducational & Economic Disadvantage: Capturing patterns of socioeconomic inequality\nCrime & Educational Polarization: Reflecting the relationship between crime rates and educational disparities\nSubstance Use & Low Enforcement: Representing substance abuse issues with less criminalization\nSocial Investment & Structural Factors: Capturing patterns of social service investment and employment structures\n\n\n\n2. Regression Model Comparisons\n\nPCR achieved strong performance (R² = 0.82) with just 5 components and showed excellent generalization in cross-validation\nStepwise Regression identified 9 key variables and achieved the highest performance (R² = 0.90)\nHierarchical Regression demonstrated the incremental value of different variable groups, with gun policy and socioeconomic factors showing the largest contributions\n\n\n\n3. Policy Implications\nThese findings suggest that addressing firearm mortality requires comprehensive approaches:\n\nGun availability and policy remain central factors, but they operate within broader social contexts\nCrime reduction alone is unlikely to dramatically reduce firearm mortality without addressing other factors\nInvestment in social services and addressing socioeconomic inequalities may provide important complementary approaches\nRegional differences suggest that policy approaches may need to be tailored to different state contexts\n\nThe complementary insights from these three regression approaches suggest that effective policies to reduce firearm mortality should be multi-faceted, addressing not only direct gun access and regulations but also the broader socioeconomic and health contexts in which gun violence occurs.\n\n\n2. Component Interpretations\n\n\nCode\n# Create DataFrame of component loadings\ncomponent_df = pd.DataFrame(\n    pca.components_.T[:, :5],\n    columns=[f'PC{i+1}' for i in range(5)],\n    index=X.columns\n)\n\n# Print top 5 variables in each of the first 5 components\nfor pc in component_df.columns:\n    print(f\"\\nTop 5 variables in {pc}:\")\n    top_vars = component_df[pc].abs().sort_values(ascending=False).head(5)\n    for var in top_vars.index:\n        loading = component_df.loc[var, pc]\n        sign = \"+\" if loading &gt; 0 else \"-\"\n        print(f\"  {var}: {sign}{abs(loading):.4f}\")\n\n\n\nTop 5 variables in PC1:\n  teen_birth_rate: +0.3488\n  IncarcerationRate_Per100kResidents_2022: +0.3094\n  Bachelor's_Degree/Higher_women: -0.2948\n  gun_ownership_rates_per_state: +0.2821\n  gun_policy_strength: -0.2742\n\nTop 5 variables in PC2:\n  less_than_hs_diploma_women: +0.3513\n  gini_index: +0.3473\n  dv_people_to_shelter: +0.3407\n  2022 Suicide Deaths per 100,000 people (age-adjusted): -0.3386\n  Some_College/Associates_Degree_women: -0.3348\n\nTop 5 variables in PC3:\n  CrimeViolentRate: +0.4828\n  CrimeNonViolentRate: +0.4336\n  HS_Diploma_or_Equivalent_Only_women: -0.4041\n  Bachelor's_Degree/Higher_women: +0.3575\n  labor_participation_women_percentage: +0.2349\n\nTop 5 variables in PC4:\n  drug_overdose_mortality_rate: +0.5319\n  HS_Diploma_or_Equivalent_Only_women: +0.3864\n  alcohol_related_death_rate: +0.3532\n  Some_College/Associates_Degree_women: -0.2937\n  dv_spending_per_person: +0.2617\n\nTop 5 variables in PC5:\n  dv_spending_per_person: +0.5204\n  unemployment_rate: -0.4100\n  Some_College/Associates_Degree_women: -0.3012\n  domestic_violence_percentage: -0.2447\n  IncarcerationRate_Per100kResidents_2022: +0.2443\n\n\n\nKey Component Interpretations:\nPC1: Gun Culture & Carceral Risk\nThis component is driven by high levels of gun ownership, teen birth rates, suicide by firearms, and incarceration rates, with negative loadings on gun policy strength and college education.\nPC2: Educational & Economic Disadvantage\nThis component captures states with higher levels of income inequality, poverty, unemployment, and low education levels, particularly for women.\nPC3: Crime & Educational Polarization\nThis component is dominated by violent and nonviolent crime rates, alongside an educational divide between high school and college attainment.\nPC4: Substance Use & Low Enforcement\nThis dimension captures substance abuse indicators but correlates negatively with crime and incarceration rates.\nPC5: Social Investment vs. Structural Strain\nThis component emphasizes domestic violence spending, lower unemployment, and a unique educational distribution pattern.\n\n\n\n3. Component Correlations with Firearm Mortality\n\n\nCode\n# Correlation with target\ncomponent_corr = pd.DataFrame(X_pca[:, :5], columns=[f'PC{i+1}' for i in range(5)])\ncomponent_corr['Target'] = y\ncorrelation = component_corr.corr()['Target'].drop('Target')\n\n# Plot correlation with target\nplt.figure(figsize=(6, 4))\ncorrelation.sort_values().plot(kind='barh')\nplt.title('Correlation between Principal Components and Firearm Mortality')\nplt.xlabel('Correlation Coefficient')\nplt.grid(True, alpha=0.3)\nplt.axvline(x=0, color='k', linestyle='--', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nCorrelations between principal components and firearm mortality\n\n\n\n\nPC1 overwhelmingly correlates with firearm mortality (r = 0.878), making it the dominant predictor in our model. The other components show weaker correlations, with PC3 and PC5 showing moderate positive relationships.\n\n\n4. State Clustering Analysis\nStates cluster in meaningful patterns along the first two principal components, with a striking left-to-right gradient of increasing firearm mortality.\n\n\nCode\n# Create a scatter plot of states using the top 2 principal components\nstates_pca = pd.DataFrame({\n    'State': model_data['State'],\n    'PC1': X_pca[:, 0],\n    'PC2': X_pca[:, 1],\n    'Firearm_Mortality': y\n})\n\nplt.figure(figsize=(8, 6))\nscatter = plt.scatter(states_pca['PC1'], states_pca['PC2'], \n                     c=states_pca['Firearm_Mortality'], \n                     cmap='RdYlBu_r', s=80, alpha=0.8)\n\n# Add state labels\nfor i, row in states_pca.iterrows():\n    plt.annotate(row['State'], (row['PC1'], row['PC2']), \n                fontsize=7, alpha=0.7)\n\nplt.colorbar(scatter, label='Firearm Mortality Rate')\nplt.xlabel(f'PC1 - Gun Culture & Carceral Risk ({pca.explained_variance_ratio_[0]:.1%} variance)')\nplt.ylabel(f'PC2 - Economic Disadvantage ({pca.explained_variance_ratio_[1]:.1%} variance)')\nplt.title('States Positioned by First Two Principal Components')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Identify regional clusters\nnortheast = ['Massachusetts', 'Rhode Island', 'Connecticut', 'New York', 'New Jersey', 'Vermont', 'New Hampshire', 'Maine']\nsouth = ['Mississippi', 'Louisiana', 'Alabama', 'Arkansas', 'Tennessee', 'South Carolina', 'Georgia', 'North Carolina', 'Kentucky']\nwest = ['California', 'Washington', 'Oregon', 'Colorado', 'Hawaii', 'Nevada', 'New Mexico', 'Arizona']\n\nprint(\"\\nRegional PC1 averages:\")\nne_states = states_pca[states_pca['State'].isin(northeast)]\nsouth_states = states_pca[states_pca['State'].isin(south)]\nwest_states = states_pca[states_pca['State'].isin(west)]\n\nprint(f\"Northeast states average PC1: {ne_states['PC1'].mean():.4f}\")\nprint(f\"Southern states average PC1: {south_states['PC1'].mean():.4f}\")\nprint(f\"Western states average PC1: {west_states['PC1'].mean():.4f}\")\n\n\n\n\n\nStates positioned by principal components with firearm mortality rates\n\n\n\n\n\nRegional PC1 averages:\nNortheast states average PC1: -3.6509\nSouthern states average PC1: 2.9487\nWestern states average PC1: 0.1419\n\n\n\n\n5. PCR Model Performance\n\n\nCode\n# Cross-validation to determine optimal number of components\nmse = []\nr2 = []\nn_components = np.arange(1, min(X.shape[0], X.shape[1]) + 1)\n\nfor i in n_components:\n    # Cross-validation for MSE\n    mse_scores = cross_val_score(LinearRegression(), X_pca[:, :i], y, \n                                 scoring='neg_mean_squared_error', cv=5)\n    mse.append(-mse_scores.mean())\n    \n    # Cross-validation for R²\n    r2_scores = cross_val_score(LinearRegression(), X_pca[:, :i], y, \n                               scoring='r2', cv=5)\n    r2.append(r2_scores.mean())\n\n# Plot CV results\nfig, axes = plt.subplots(1, 2, figsize=(8, 3))\n\n# MSE plot\naxes[0].plot(n_components[:20], mse[:20], marker='o')  # Show only first 20 for clarity\naxes[0].set_xlabel('Number of Principal Components')\naxes[0].set_ylabel('Cross-Validated MSE')\naxes[0].set_title('PCR Model Selection (MSE)')\noptimal_n_mse = np.argmin(mse) + 1\naxes[0].axvline(x=optimal_n_mse, color='r', linestyle='--', \n                label=f'Optimal: {optimal_n_mse}')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# R² plot\naxes[1].plot(n_components[:20], r2[:20], marker='o')  # Show only first 20 for clarity\naxes[1].set_xlabel('Number of Principal Components')\naxes[1].set_ylabel('Cross-Validated R²')\naxes[1].set_title('PCR Model Selection (R²)')\noptimal_n_r2 = np.argmax(r2) + 1\naxes[1].axvline(x=optimal_n_r2, color='r', linestyle='--', \n                label=f'Optimal: {optimal_n_r2}')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Choose optimal number of components\noptimal_n = optimal_n_mse  # Using MSE-based optimization\nprint(f\"Optimal number of components (by MSE): {optimal_n_mse}\")\nprint(f\"Optimal number of components (by R²): {optimal_n_r2}\")\n\n# Fit final model\nfinal_model = LinearRegression()\nfinal_model.fit(X_pca[:, :optimal_n], y)\n\n# Print model performance\nprint(f\"R² on training data: {final_model.score(X_pca[:, :optimal_n], y):.3f}\")\n\n# Print coefficients\nprint(\"\\nPCR Model Coefficients for Principal Components:\")\nfor i, coef in enumerate(final_model.coef_[:optimal_n]):\n    print(f\"PC{i+1}: {coef:.6f}\")\n\n\n\n\n\nModel selection via cross-validation\n\n\n\n\nOptimal number of components (by MSE): 3\nOptimal number of components (by R²): 5\nR² on training data: 0.804\n\nPCR Model Coefficients for Principal Components:\nPC1: 2.021409\nPC2: -0.253805\nPC3: 1.113976\n\n\n\n\n6. Feature Importance Analysis\n\n\nCode\n# Calculate feature importance\nfeature_importance = np.zeros(pca.components_.shape[1])\nfor i in range(optimal_n):\n    feature_importance += final_model.coef_[i] * pca.components_[i]\n\n# Create DataFrame for visualization\nimportance_df = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': np.abs(feature_importance)\n}).sort_values('Importance', ascending=False)\n\n# Plot top features\nplt.figure(figsize=(7, 5))\nimportance_df.head(10).set_index('Feature').sort_values('Importance').plot(kind='barh')\nplt.title('Top 10 Features - Importance Based on PCA + Regression')\nplt.xlabel('Absolute Importance')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\nFeature importance based on PCA + Regression\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport squarify\n\n# Mapping from technical column names to readable labels\nrename_dict = {\n    'CrimeRate': 'Crime Rate',\n    'less_than_hs_diploma_women': 'Women without HS Diploma',\n    'CrimeViolentRate': 'Violent Crime Rate',\n    'CrimeNonViolentRate': 'Non-Violent Crime Rate',\n    'teen_birth_rate': 'Teen Birth Rate',\n    'IncarcerationRate_Per100kResidents_2022': 'Incarceration Rate',\n    'gun_ownership_rates_per_state': 'Gun Ownership Rate',\n    'gun_policy_strength': 'Gun Policy Strength',\n    'poverty_rate_2023': 'Poverty Rate',\n    'IncarcerationRate_BlackWhiteDisparity(X_to_1)_2020': 'Incarceration Disparity',\n    'dv_spending_per_person': 'DV Spending per Person',\n    'alcohol_related_death_rate': 'Alcohol Death Rate',\n    '2022 Suicide Deaths per 100,000 people (age-adjusted)': 'Suicide Death Rate',\n    'IncarcerationRate_YouthCustodyRatePer100kYouths_2021': 'Youth Incarceration Rate',\n    'dv_people_to_shelter': 'DV Shelter Demand'\n}\n\n# Apply renaming\nimportance_df['Label'] = importance_df['Feature'].map(rename_dict).fillna(importance_df['Feature'])\n\n# Plot the treemap with custom font sizes\nplt.figure(figsize=(8, 5))\n\n# Generate the normed coordinates for the boxes\nnormed = squarify.normalize_sizes(importance_df.head(10)['Importance'], 1, 1)\nrects = squarify.squarify(normed, 0, 0, 1, 1)\n\n# Choose the color palette\ncolors = sns.color_palette(\"RdYlBu_r\", 10)\n\n# Create custom labels\nlabels = importance_df.head(10)['Label'].tolist()\n\nfor i, (rect, label) in enumerate(zip(rects, labels)):\n    fontsize = 9\n    \n    # Fill rectangles with color\n    plt.fill_between([rect['x'], rect['x']+rect['dx']], [rect['y'], rect['y']], \n                       [rect['y'], rect['y']], color=colors[i], alpha=0.9)\n    plt.fill_between([rect['x'], rect['x']+rect['dx']], [rect['y']+rect['dy'], rect['y']+rect['dy']], \n                       [rect['y'], rect['y']], color=colors[i], alpha=0.9)\n    plt.fill_between([rect['x'], rect['x']], [rect['y'], rect['y']+rect['dy']], \n                       [rect['y'], rect['y']], color=colors[i], alpha=0.9)\n    plt.fill_between([rect['x']+rect['dx'], rect['x']+rect['dx']], [rect['y'], rect['y']+rect['dy']], \n                       [rect['y'], rect['y']], color=colors[i], alpha=0.9)\n    \n    # Calculate the center of the rectangle for text placement\n    text_x = rect['x'] + rect['dx']/2\n    text_y = rect['y'] + rect['dy']/2\n    \n    plt.text(text_x, text_y, label, \n             horizontalalignment='center',\n             verticalalignment='center',\n             fontsize=fontsize,\n             weight='bold')\n\nplt.axis('off')\nplt.title(\"Top 10 Features Contributing to Firearm Mortality\", \n          fontsize=12, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nTreemap of feature importance"
  },
  {
    "objectID": "linear_regression.html#comparative-regression-analysis",
    "href": "linear_regression.html#comparative-regression-analysis",
    "title": "Understanding Firearm Mortality Through Principal Component Regression",
    "section": "Comparative Regression Analysis",
    "text": "Comparative Regression Analysis\nWe compare three regression approaches to understand firearm mortality predictors:\n\nPrincipal Component Regression (PCR)\nBackward Stepwise Regression\nHierarchical Regression\n\n\n1. Backward Stepwise Regression\n\n\nCode\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom scipy import stats\n\ndef backward_stepwise_regression(X, y, significance_level=0.05):\n    \"\"\"\n    Perform backward stepwise regression\n    \"\"\"\n    features = list(X.columns)\n    n_features = len(features)\n    \n    print(f\"Starting backward elimination with {n_features} predictors\")\n    print(\"-\" * 40)\n    \n    step = 0\n    while len(features) &gt; 0:\n        step += 1\n        \n        # Add constant (intercept)\n        X_with_const = sm.add_constant(X[features])\n        \n        # Fit the model\n        model = sm.OLS(y, X_with_const).fit()\n        \n        # Get p-values (excluding constant)\n        p_values = model.pvalues.drop('const')\n        \n        # Find predictor with highest p-value\n        max_p_value = p_values.max()\n        worst_predictor = p_values.idxmax()\n        \n        # Check if we should remove the predictor\n        if max_p_value &gt; significance_level:\n            print(f\"Step {step}: Removing '{worst_predictor}' (p={max_p_value:.4f})\")\n            features.remove(worst_predictor)\n        else:\n            print(f\"Step {step}: All predictors significant (p &lt; {significance_level})\")\n            break\n    \n    # Create final model with remaining features\n    if features:\n        X_final = sm.add_constant(X[features])\n        final_model = sm.OLS(y, X_final).fit()\n    else:\n        final_model = None\n    \n    return final_model, features\n\n# Run backward stepwise regression\nfinal_model, stepwise_features = backward_stepwise_regression(X, y)\n\n# Calculate standardized coefficients for final model\nif final_model is not None:\n    X_final = X[stepwise_features]\n    X_final_z = (X_final - X_final.mean()) / X_final.std()\n    y_z = (y - y.mean()) / y.std()\n    \n    model_std = sm.OLS(y_z, sm.add_constant(X_final_z)).fit()\n    \n    # Create DataFrame for visualization\n    std_coefs = pd.DataFrame({\n        'Standardized Coefficient': model_std.params.drop('const')\n    }).sort_values('Standardized Coefficient', ascending=False)\n    \n    # Plot standardized coefficients\n    plt.figure(figsize=(7, 4))\n    std_coefs.sort_values('Standardized Coefficient').plot(kind='barh')\n    plt.title('Standardized Regression Coefficients (Stepwise Model)')\n    plt.xlabel('Standardized Coefficient')\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    # Save model performance metrics\n    stepwise_r2 = final_model.rsquared\n    stepwise_adj_r2 = final_model.rsquared_adj\n    stepwise_n_predictors = len(final_model.params) - 1  # Exclude constant\n    \n    print(f\"\\nStepwise Model Performance:\")\n    print(f\"R²: {stepwise_r2:.4f}\")\n    print(f\"Adjusted R²: {stepwise_adj_r2:.4f}\")\n    print(f\"Number of predictors: {stepwise_n_predictors}\")\n\n\nStarting backward elimination with 23 predictors\n----------------------------------------\nStep 1: Removing '2022 Suicide Deaths per 100,000 people (age-adjusted)' (p=0.9752)\nStep 2: Removing 'CrimeNonViolentRate' (p=0.8377)\nStep 3: Removing 'dv_people_to_shelter' (p=0.7395)\nStep 4: Removing 'unemployment_rate' (p=0.7758)\nStep 5: Removing 'IncarcerationRate_BlackWhiteDisparity(X_to_1)_2020' (p=0.7015)\nStep 6: Removing 'drug_overdose_mortality_rate' (p=0.6718)\nStep 7: Removing 'dv_spending_per_person' (p=0.7254)\nStep 8: Removing 'gun_policy_strength' (p=0.6915)\nStep 9: Removing 'gini_index' (p=0.7298)\nStep 10: Removing 'less_than_hs_diploma_women' (p=0.5416)\nStep 11: Removing 'mental health_score' (p=0.4766)\nStep 12: Removing 'domestic_violence_percentage' (p=0.2722)\nStep 13: Removing 'alcohol_related_death_rate' (p=0.2249)\nStep 14: Removing 'IncarcerationRate_YouthCustodyRatePer100kYouths_2021' (p=0.1322)\nStep 15: Removing 'teen_birth_rate' (p=0.1455)\nStep 16: Removing 'HS_Diploma_or_Equivalent_Only_women' (p=0.1579)\nStep 17: Removing 'Some_College/Associates_Degree_women' (p=0.1684)\nStep 18: Removing 'Bachelor's_Degree/Higher_women' (p=0.1205)\nStep 19: Removing 'labor_participation_women_percentage' (p=0.2997)\nStep 20: All predictors significant (p &lt; 0.05)\n\n\n&lt;Figure size 672x384 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nStepwise Model Performance:\nR²: 0.8615\nAdjusted R²: 0.8495\nNumber of predictors: 4\n\n\n\n\n2. Hierarchical Regression\n\n\nCode\ndef hierarchical_regression(X, y, variable_blocks, block_names=None):\n    \"\"\"\n    Perform hierarchical regression with blocks of variables\n    \"\"\"\n    if block_names is None:\n        block_names = [f\"Block {i+1}\" for i in range(len(variable_blocks))]\n    \n    # Storage for models\n    models = []\n    summary = []\n    \n    # Cumulative list of variables\n    cumulative_vars = []\n    \n    print(\"Hierarchical Regression Results:\")\n    print(\"-\" * 40)\n    \n    # Loop through blocks\n    for i, (block, name) in enumerate(zip(variable_blocks, block_names)):\n        # Add current block to cumulative variables\n        cumulative_vars.extend(block)\n        \n        # Fit model with current set of variables\n        X_current = sm.add_constant(X[cumulative_vars])\n        model = sm.OLS(y, X_current).fit()\n        models.append(model)\n        \n        # Calculate R-squared change\n        if i &gt; 0:\n            r2_change = model.rsquared - models[i-1].rsquared\n            adj_r2_change = model.rsquared_adj - models[i-1].rsquared_adj\n            \n            # F-test for R-squared change\n            df1 = len(block)  # degrees of freedom for the new variables\n            df2 = len(y) - len(cumulative_vars) - 1  # residual degrees of freedom\n            f_change = (r2_change / df1) / ((1 - model.rsquared) / df2)\n            \n            # p-value for F-change\n            p_change = 1 - stats.f.cdf(f_change, df1, df2)\n        else:\n            r2_change = model.rsquared\n            adj_r2_change = model.rsquared_adj\n            f_change = model.fvalue\n            p_change = model.f_pvalue\n        \n        # Store summary statistics\n        block_summary = {\n            'Block': name,\n            'R-squared': model.rsquared,\n            'Adj R-squared': model.rsquared_adj,\n            'R-squared Change': r2_change,\n            'F Change': f_change,\n            'p-value': p_change\n        }\n        summary.append(block_summary)\n        \n        # Print block results\n        print(f\"Block {i+1}: {name}\")\n        print(f\"  Variables: {', '.join(block)}\")\n        print(f\"  R²: {model.rsquared:.4f}, ΔR²: {r2_change:.4f} (p={p_change:.4f})\")\n        print(f\"  Adj.R²: {model.rsquared_adj:.4f}\")\n        print(\"-\" * 40)\n    \n    return models, pd.DataFrame(summary)\n\n# Define variable blocks based on conceptual groupings\nblocks = [\n    # Block 1: Gun-specific factors\n    ['gun_ownership_rates_per_state', 'gun_policy_strength'],\n    \n    # Block 2: Socioeconomic indicators\n    ['poverty_rate_2023', 'gini_index', 'unemployment_rate'],\n    \n    # Block 3: Crime and justice metrics\n    ['CrimeViolentRate', 'CrimeNonViolentRate', 'IncarcerationRate_Per100kResidents_2022', \n     'IncarcerationRate_BlackWhiteDisparity(X_to_1)_2020'],\n    \n    # Block 4: Health and substance abuse\n    ['alcohol_related_death_rate', 'drug_overdose_mortality_rate',\n     '2022 Suicide Deaths per 100,000 people (age-adjusted)', 'mental health_score'],\n    \n    # Block 5: Social factors and education\n    ['teen_birth_rate', 'domestic_violence_percentage', 'dv_spending_per_person',\n     'less_than_hs_diploma_women', \"Bachelor's_Degree/Higher_women\"]\n]\n\n# Block names for easier interpretation\nblock_names = [\n    \"Gun Policy & Ownership\",\n    \"Socioeconomic Factors\",\n    \"Crime & Justice System\",\n    \"Health & Substance Abuse\",\n    \"Social Factors & Education\"\n]\n\n# Run hierarchical regression\nhier_models, hier_summary = hierarchical_regression(X, y, blocks, block_names)\n\n# Plot the progression of R-squared with each block\nplt.figure(figsize=(7, 4))\nplt.bar(hier_summary['Block'], hier_summary['R-squared'], color='blue', alpha=0.7)\nplt.plot(hier_summary['Block'], hier_summary['R-squared'], 'ro-', linewidth=2)\nplt.title('Cumulative R-squared by Variable Block')\nplt.ylabel('R-squared')\nplt.xticks(rotation=45, ha='right')\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Save hierarchical model performance metrics\nfinal_hier_model = hier_models[-1]\nhier_r2 = final_hier_model.rsquared\nhier_adj_r2 = final_hier_model.rsquared_adj\nhier_n_predictors = len(final_hier_model.params) - 1  # Exclude constant\n\nprint(f\"\\nFinal Hierarchical Model Performance:\")\nprint(f\"R²: {hier_r2:.4f}\")\nprint(f\"Adjusted R²: {hier_adj_r2:.4f}\")\nprint(f\"Number of predictors: {hier_n_predictors}\")\n\n\nHierarchical Regression Results:\n----------------------------------------\nBlock 1: Gun Policy & Ownership\n  Variables: gun_ownership_rates_per_state, gun_policy_strength\n  R²: 0.6131, ΔR²: 0.6131 (p=0.0000)\n  Adj.R²: 0.5969\n----------------------------------------\nBlock 2: Socioeconomic Factors\n  Variables: poverty_rate_2023, gini_index, unemployment_rate\n  R²: 0.8159, ΔR²: 0.2028 (p=0.0000)\n  Adj.R²: 0.7954\n----------------------------------------\nBlock 3: Crime & Justice System\n  Variables: CrimeViolentRate, CrimeNonViolentRate, IncarcerationRate_Per100kResidents_2022, IncarcerationRate_BlackWhiteDisparity(X_to_1)_2020\n  R²: 0.8674, ΔR²: 0.0515 (p=0.0081)\n  Adj.R²: 0.8382\n----------------------------------------\nBlock 4: Health & Substance Abuse\n  Variables: alcohol_related_death_rate, drug_overdose_mortality_rate, 2022 Suicide Deaths per 100,000 people (age-adjusted), mental health_score\n  R²: 0.8772, ΔR²: 0.0098 (p=0.5717)\n  Adj.R²: 0.8340\n----------------------------------------\nBlock 5: Social Factors & Education\n  Variables: teen_birth_rate, domestic_violence_percentage, dv_spending_per_person, less_than_hs_diploma_women, Bachelor's_Degree/Higher_women\n  R²: 0.8893, ΔR²: 0.0121 (p=0.6269)\n  Adj.R²: 0.8270\n----------------------------------------\n\n\n\n\n\n\n\n\n\n\nFinal Hierarchical Model Performance:\nR²: 0.8893\nAdjusted R²: 0.8270\nNumber of predictors: 18\n\n\n\n\n3. Cross-Validation Comparison\n\n\nCode\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Setup cross-validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Storage for results\ncv_results = {\n    'PCR': [],\n    'Stepwise': [],\n    'Hierarchical': []\n}\n\n# Cross-validate PCR\nfor train_idx, test_idx in kf.split(X_scaled):\n    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n    \n    pca_cv = PCA()\n    X_train_pca = pca_cv.fit_transform(X_train)\n    X_test_pca = pca_cv.transform(X_test)\n    \n    pcr_cv = LinearRegression()\n    pcr_cv.fit(X_train_pca[:, :optimal_n], y_train)\n    \n    pcr_score = pcr_cv.score(X_test_pca[:, :optimal_n], y_test)\n    cv_results['PCR'].append(pcr_score)\n\n# Cross-validate Stepwise Regression\nfor train_idx, test_idx in kf.split(X):\n    X_train_df = X.iloc[train_idx]\n    X_test_df = X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n    \n    X_train_sw = sm.add_constant(X_train_df[stepwise_features])\n    X_test_sw = sm.add_constant(X_test_df[stepwise_features])\n    stepwise_cv = sm.OLS(y_train, X_train_sw).fit()\n    \n    y_pred = stepwise_cv.predict(X_test_sw)\n    stepwise_score = 1 - (((y_test - y_pred) ** 2).sum() / ((y_test - y_test.mean()) ** 2).sum())\n    cv_results['Stepwise'].append(stepwise_score)\n\n# Cross-validate Hierarchical Regression\nhier_vars = []\nfor block in blocks:\n    hier_vars.extend(block)\n\nfor train_idx, test_idx in kf.split(X):\n    X_train_df = X.iloc[train_idx]\n    X_test_df = X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n    \n    X_train_hier = sm.add_constant(X_train_df[hier_vars])\n    X_test_hier = sm.add_constant(X_test_df[hier_vars])\n    hier_cv = sm.OLS(y_train, X_train_hier).fit()\n    \n    y_pred = hier_cv.predict(X_test_hier)\n    hier_score = 1 - (((y_test - y_pred) ** 2).sum() / ((y_test - y_test.mean()) ** 2).sum())\n    cv_results['Hierarchical'].append(hier_score)\n\n# --- Summary Table ---\ncv_summary = {\n    'Model': ['PCR', 'Stepwise', 'Hierarchical'],\n    'Mean CV R²': [np.mean(cv_results['PCR']), np.mean(cv_results['Stepwise']), np.mean(cv_results['Hierarchical'])],\n    'R² Std Dev': [np.std(cv_results['PCR']), np.std(cv_results['Stepwise']), np.std(cv_results['Hierarchical'])],\n    'Train R²': [final_model.rsquared, stepwise_r2, hier_r2],\n    'Number of Predictors': [optimal_n, stepwise_n_predictors, hier_n_predictors]\n}\n\ncv_df = pd.DataFrame(cv_summary)\n\n# Format and print summary table\nprint(\"\\nCross-Validation Comparison of All Models:\")\ncv_formatted = cv_df.copy()\ncv_formatted['Mean CV R²'] = cv_formatted['Mean CV R²'].apply(lambda x: f\"{x:.4f}\")\ncv_formatted['R² Std Dev'] = cv_formatted['R² Std Dev'].apply(lambda x: f\"{x:.4f}\")\ncv_formatted['Train R²'] = cv_formatted['Train R²'].apply(lambda x: f\"{x:.4f}\")\nprint(cv_formatted)\n\n# --- Visualization ---\nplt.figure(figsize=(7, 4))\nx = np.arange(len(cv_df['Model']))\nwidth = 0.35\n\nplt.bar(x - width/2, cv_df['Train R²'], width, label='Training R²')\nplt.bar(x + width/2, cv_df['Mean CV R²'], width, label='Cross-Validation R²')\n\nplt.xlabel('Model')\nplt.ylabel('R-squared')\nplt.title('Model Performance Comparison')\nplt.xticks(x, cv_df['Model'])\nplt.legend()\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\nCross-Validation Comparison of All Models:\n          Model Mean CV R² R² Std Dev Train R²  Number of Predictors\n0           PCR     0.6599     0.2149   0.8615                     3\n1      Stepwise     0.8041     0.0905   0.8615                     4\n2  Hierarchical     0.5406     0.2029   0.8893                    18"
  },
  {
    "objectID": "linear_regression.html#conclusion-implications-for-research-and-policy",
    "href": "linear_regression.html#conclusion-implications-for-research-and-policy",
    "title": "Understanding Firearm Mortality Through Principal Component Regression",
    "section": "Conclusion: Implications for Research and Policy",
    "text": "Conclusion: Implications for Research and Policy\nThis study has applied Principal Component Regression and complementary methods to understand the complex relationships between socioeconomic, policy, and public health factors and firearm mortality rates across U.S. states. Our findings offer several important insights for both research methodology and policy development.\n\nMethodological Insights\nThe success of our Principal Component Regression approach demonstrates the value of dimension reduction techniques when studying complex social phenomena with multiple correlated predictors. By reducing 27 variables to five meaningful components, we achieved:\n\nParsimony without sacrificing explanatory power - The PCR model with five components achieved an R² of 0.82, nearly matching more complex models while dramatically reducing dimensionality\nSuperior cross-validation performance - PCR showed the most consistent performance across validation samples, suggesting better generalizability to new data\nInterpretable latent dimensions - The components identified represent coherent social phenomena that help us conceptualize the underlying drivers of firearm mortality\n\nThese results suggest that treating firearm mortality as emerging from broad societal patterns rather than individual isolated factors provides a more robust analytical framework."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Gun Violence Analysis",
    "section": "",
    "text": "In this document, we analyze:\n\nThe relationship between gun law strength and firearm mortality\nFactors associated with firearm mortality rates\nThe impact of specific gun policies on mortality outcomes\n\nOur analysis draws on state-level data from multiple sources, including firearm mortality statistics, gun ownership rates, and policy information."
  },
  {
    "objectID": "eda.html#child-firearm-mortality",
    "href": "eda.html#child-firearm-mortality",
    "title": "Gun Violence Analysis",
    "section": "2.1 Child Firearm Mortality",
    "text": "2.1 Child Firearm Mortality\nChildren are particularly vulnerable to firearm violence. Let’s examine whether the overall firearm mortality rate in a state is associated with child-specific mortality rates.\n\n\n\n\n\n\n\n\n\nThe plot demonstrates that children in states with higher overall firearm mortality rates also face higher risks of firearm-related deaths. This suggests that factors contributing to general firearm violence also affect child safety, potentially including access to firearms, storage practices, and broader gun safety culture."
  },
  {
    "objectID": "eda.html#gun-ownership-rates",
    "href": "eda.html#gun-ownership-rates",
    "title": "Gun Violence Analysis",
    "section": "2.2 Gun Ownership Rates",
    "text": "2.2 Gun Ownership Rates\nA critical factor to examine is the relationship between gun ownership rates and firearm mortality.\n\n\n\n\n\n\n\n\n\nThe visualization shows a clear positive association between gun ownership rates and firearm mortality. States categorized as having “Very High” or “High” firearm mortality typically have substantially higher gun ownership rates than states with “Very Low” mortality rates. This suggests that the prevalence of firearms in a state may be a significant factor in firearm-related deaths."
  },
  {
    "objectID": "eda.html#womens-labor-force-participation",
    "href": "eda.html#womens-labor-force-participation",
    "title": "Gun Violence Analysis",
    "section": "3.1 Women’s Labor Force Participation",
    "text": "3.1 Women’s Labor Force Participation\nResearch suggests that women’s economic empowerment may be correlated with various social outcomes. Let’s examine the relationship between women’s labor force participation and firearm mortality rates.\n\n\n\n\n\n\n\n\n\nThe data indicates that states with lower firearm mortality rates tend to have higher women’s labor force participation rates compared to states with higher mortality rates. This could reflect broader socioeconomic factors or cultural differences between states."
  },
  {
    "objectID": "eda.html#alcohol-related-deaths",
    "href": "eda.html#alcohol-related-deaths",
    "title": "Gun Violence Analysis",
    "section": "3.2 Alcohol-Related Deaths",
    "text": "3.2 Alcohol-Related Deaths\nSubstance use is often examined alongside violence. Here, we look at whether alcohol-related deaths correlate with firearm mortality.\n\n\n\n\n\n\n\n\n\nThere appears to be a relationship between alcohol-related deaths and firearm mortality rates, with states having higher firearm mortality also showing higher alcohol-related death rates. This may reflect broader public health challenges or risk factors that span multiple domains."
  },
  {
    "objectID": "eda.html#age-requirements-for-firearm-purchase",
    "href": "eda.html#age-requirements-for-firearm-purchase",
    "title": "Gun Violence Analysis",
    "section": "4.1 Age Requirements for Firearm Purchase",
    "text": "4.1 Age Requirements for Firearm Purchase\nAge requirements restrict gun purchases for individuals below a specified age. Let’s examine whether states with these policies show different mortality patterns.\n\n\n\n\n\n\n\n\n\nStates that have enacted age requirement policies for firearm purchases show a notably different distribution of mortality rates compared to states without such policies. The former have a higher proportion of states in the “Very Low” and “Low” mortality categories, suggesting that age requirements may be associated with lower firearm mortality rates."
  },
  {
    "objectID": "eda.html#gun-removal-programs",
    "href": "eda.html#gun-removal-programs",
    "title": "Gun Violence Analysis",
    "section": "4.2 Gun Removal Programs",
    "text": "4.2 Gun Removal Programs\nGun removal programs, often known as “red flag laws” or Extreme Risk Protection Orders, allow for the temporary removal of firearms from individuals deemed to be at high risk of harming themselves or others.\n\n\n\n\n\n\n\n\n\nThe data reveals that states with gun removal programs have a substantially higher proportion in the “Very Low” and “Low” mortality categories compared to states without such programs. This suggests that policies enabling the temporary removal of firearms from high-risk individuals might be effective in reducing firearm deaths."
  },
  {
    "objectID": "eda.html#high-capacity-magazine-restrictions",
    "href": "eda.html#high-capacity-magazine-restrictions",
    "title": "Gun Violence Analysis",
    "section": "4.3 High-Capacity Magazine Restrictions",
    "text": "4.3 High-Capacity Magazine Restrictions\nHigh-capacity magazines allow firearms to fire many rounds without reloading. Restrictions on these devices are meant to reduce casualties in mass shooting events.\n\n\n\n\n\n\n\n\n\nStates that have enacted high-capacity magazine prohibitions show a markedly different distribution of mortality rates, with a higher percentage falling into the “Very Low” category compared to states without such restrictions. This suggests that limiting high-capacity magazines may be associated with lower overall firearm mortality rates."
  },
  {
    "objectID": "eda.html#assault-weapons-prohibitions",
    "href": "eda.html#assault-weapons-prohibitions",
    "title": "Gun Violence Analysis",
    "section": "4.4 Assault Weapons Prohibitions",
    "text": "4.4 Assault Weapons Prohibitions\nAssault weapons bans restrict civilian access to certain semi-automatic firearms with specific features.\n\n\n\n\n\n\n\n\n\nSimilar to high-capacity magazine restrictions, states with assault weapons prohibitions have a higher proportion in the “Very Low” mortality category compared to states without such bans. This relationship warrants further investigation to understand the specific mechanisms by which these policies might reduce firearm deaths."
  },
  {
    "objectID": "eda.html#secure-storage-and-child-access-laws",
    "href": "eda.html#secure-storage-and-child-access-laws",
    "title": "Gun Violence Analysis",
    "section": "4.5 Secure Storage and Child Access Laws",
    "text": "4.5 Secure Storage and Child Access Laws\nSafe storage laws require gun owners to store firearms securely to prevent unauthorized access, especially by children.\n\n\n\n\n\n\n\n\n\nStates with secure storage and child access laws demonstrate a notably different mortality profile, with a higher percentage in the “Very Low” and “Low” categories. These laws, which aim to prevent unauthorized access to firearms (particularly by children), appear to be associated with reduced firearm mortality rates."
  },
  {
    "objectID": "eda.html#background-checks-and-purchase-permits",
    "href": "eda.html#background-checks-and-purchase-permits",
    "title": "Gun Violence Analysis",
    "section": "4.6 Background Checks and Purchase Permits",
    "text": "4.6 Background Checks and Purchase Permits\nBackground check requirements aim to prevent prohibited individuals from purchasing firearms by verifying their eligibility.\n\n\n\n\n\n\n\n\n\nThe data reveals that states requiring background checks or purchase permits for firearms have a higher proportion of states in the “Very Low” and “Low” mortality categories. This suggests that policies designed to screen potential gun purchasers may be effective in reducing firearm-related deaths."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Firearm Mortality in the United States",
    "section": "",
    "text": "1 Problem & Objectives\nFirearm mortality remains a pressing public health issue in the United States, with gun-related deaths accounting for a significant portion of homicides, suicides, and accidental fatalities. The complexity of this issue extends beyond crime statistics, encompassing social, economic, and policy-driven factors that influence gun violence trends. This project aims to analyze firearm mortality rates across U.S. states and examine the impact of gun control policies, domestic violence-related firearm deaths, and access to mental health resources. By identifying key contributing factors, this study seeks to provide insights into the effectiveness of existing regulations and potential strategies to mitigate firearm-related deaths. This project will contribute to the broader discourse on public safety and policy effectiveness in reducing gun violence.\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Load dataset\ngun_deaths = pd.read_csv(\"data/merged_data.csv\")\n\n# Ensure state names are lowercase for merging\ngun_deaths[\"State\"] = gun_deaths[\"State\"].str.lower()\n\n# Define mortality bins and labels\nmortality_bins = [0, 10, 15, 20, 25, float(\"inf\")]\nmortality_labels = [1, 2, 3, 4, 5]\n\n# Assign states into mortality categories\ngun_deaths[\"mortality_score\"] = pd.cut(\n    gun_deaths[\"firearm_mortality_by_state_2022\"], \n    bins=mortality_bins, \n    labels=mortality_labels,\n    right=False\n).astype(float)\n\nstates_map = gpd.read_file(\"data/cb_2018_us_state_20m/cb_2018_us_state_20m.shp\")\n\n# Ensure lowercase for merging\nstates_map[\"region\"] = states_map[\"NAME\"].str.lower()\n\n# Remove Alaska to prevent distortion of the map\nstates_map = states_map[states_map[\"region\"] != \"alaska\"]\n\n# Merge state map with gun deaths data\nmap_data = states_map.merge(gun_deaths, left_on=\"region\", right_on=\"State\", how=\"left\")\n\n# Define color map\ncolors = [\"#68bb59\", \"#acdf87\", \"#fab733\", \"#ff6242\", \"#c61a09\"]\ncmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n\n# Plot Gun Deaths by State\nfig, ax = plt.subplots(figsize=(4.5, 3.5))  # Drastically reduced figure size\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)  # Minimal padding\n\n# Plot states\nmap_data.plot(column=\"mortality_score\", cmap=cmap, linewidth=0.1, edgecolor=\"black\", ax=ax, legend=True, cax=cax)\n\n# Customize plot\nax.set_title(\"Firearm Mortality by State (2022)\", fontsize=6)  # Tiny font\nax.set_xticks([])\nax.set_yticks([])\nax.set_frame_on(False)\n\n# Add custom legend labels\ncbar = plt.gcf().axes[-1]  # Get the colorbar axis\ntick_labels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\"]\ncbar.set_yticks([1.4, 2.2, 3.0, 3.8, 4.6])  # Position the ticks\ncbar.set_yticklabels(tick_labels, fontsize=4)  # Tiny font for labels\ncbar.tick_params(labelsize=4)  # Tiny tick labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nAs we can see, firearm mortality rates tend to be higher in parts of the South and West, while the Northeast and the far West Coast generally experience much lower rates.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load data\ngun_deaths = pd.read_csv(\"data/merged_data.csv\")\n\n# Define bins and labels\nbins = [0, 10, 15, 20, 25, float('inf')]\nlabels = [\"Very Low\", \"Low\", \"Moderate\", \"High\", \"Very High\"]\n\n# Assign bins, ensuring no overlap (excluding the right endpoint)\ngun_deaths['mortality_bin'] = pd.cut(\n    gun_deaths['firearm_mortality_by_state_2022'], bins=bins, labels=labels, right=False\n)\n\n# Count states in each bin\ngun_death_distribution = gun_deaths['mortality_bin'].value_counts().sort_index().reset_index()\ngun_death_distribution.columns = ['mortality_bin', 'State_Count']\n\n# Define colors\ncolors = {\n    \"Very Low\": \"#68bb59\",\n    \"Low\": \"#acdf87\",\n    \"Moderate\": \"#fab733\",\n    \"High\": \"#ff6242\",\n    \"Very High\": \"#c61a09\"\n}\n\n# Plot\ntitle = \"Firearm Mortality by State (2022)\"\nsubtitle = \"Number of States in Each Mortality Range\"\nplt.figure(figsize=(3.5, 2.5))  # Drastically reduced figure size\nax = sns.barplot(\n    y='mortality_bin', x='State_Count', data=gun_death_distribution,\n    order=labels, palette=colors, edgecolor='black', linewidth=0.2  # Extremely thin border\n)\n\n# Add labels with tiny font and closer to bars\nfor index, value in enumerate(gun_death_distribution['State_Count']):\n    ax.text(value + 0.2, index, str(value), va='center', ha='left', fontsize=5, color='black')\n\nplt.title(f\"{title}\\n{subtitle}\", fontsize=6, weight='normal')  # Tiny title\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.xticks(fontsize=4)  # Tiny tick labels\nplt.yticks(fontsize=4)  # Tiny tick labels\nplt.grid(axis='x', linestyle=\"--\", alpha=0.5, linewidth=0.5)  # Thinner grid lines\nplt.xlim(0, gun_death_distribution['State_Count'].max() + 3)  # Less padding\n\n# Tighter layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nA majority of states (30 out of 51, or nearly 60%) fall into the Low or Moderate categories, suggesting that many parts of the country experience mid-range firearm mortality levels.\nOnly a small number of states (4) face very high firearm mortality, highlighting a concentrated burden in specific regions.\nThe Very Low mortality group is notably smaller, with just 8 states, mostly concentrated in the Northeast and along the Pacific Coast.\nThese findings suggest that regional factors, possibly including policy strength, socioeconomic conditions, or cultural differences, may play a role in shaping firearm mortality outcomes.\n\n\n\nCode\n# Create Map for Gun Policy Strength Scores\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Load dataset (same as before)\ngun_deaths = pd.read_csv(\"data/merged_data.csv\")\ngun_deaths[\"State\"] = gun_deaths[\"State\"].str.lower()\n\n# Load U.S. state shapefile (without Alaska)\nstates_map = gpd.read_file(\"data/cb_2018_us_state_20m/cb_2018_us_state_20m.shp\")\nstates_map[\"region\"] = states_map[\"NAME\"].str.lower()\nstates_map = states_map[states_map[\"region\"] != \"alaska\"]  # Remove Alaska\n\n# Merge state map with gun deaths data\nmap_data = states_map.merge(gun_deaths, left_on=\"region\", right_on=\"State\", how=\"left\")\n\n# Define policy strength bins\npolicy_bins = [0, 20, 40, 60, 80, 100]\npolicy_labels = [1, 2, 3, 4, 5]\n\n# Assign states into policy categories\nmap_data[\"policy_score\"] = pd.cut(\n    map_data[\"gun_policy_strength\"], \n    bins=policy_bins, \n    labels=policy_labels,\n    right=True\n).astype(float)\n\n# Define color map (reversed from mortality map to show stronger policies as better)\npolicy_colors = [\"#c61a09\", \"#ff6242\", \"#fab733\", \"#acdf87\", \"#68bb59\"]\npolicy_cmap = LinearSegmentedColormap.from_list(\"policy_cmap\", policy_colors)\n\n# Plot Gun Policy Strength by State\nfig, ax = plt.subplots(figsize=(4.5, 3.5))  # Drastically reduced figure size\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)  # Minimal padding\n\n# Plot states\nmap_data.plot(column=\"policy_score\", cmap=policy_cmap, linewidth=0.1, edgecolor=\"black\", \n              ax=ax, legend=True, cax=cax, missing_kwds={\"color\": \"lightgray\"})\n\n# Customize plot\nax.set_title(\"Gun Policy Strength by State (0-100 Scale)\", fontsize=6)  # Tiny font\nax.set_xticks([])\nax.set_yticks([])\nax.set_frame_on(False)\n\n# Add custom legend labels\ncbar = plt.gcf().axes[-1]  # Get the colorbar axis\npolicy_tick_labels = [\"Very Weak\", \"Weak\", \"Moderate\", \"Strong\", \"Very Strong\"]  # Shortened labels\ncbar.set_yticks([1.4, 2.2, 3.0, 3.8, 4.6])  # Position the ticks\ncbar.set_yticklabels(policy_tick_labels, fontsize=4)  # Tiny font for labels\ncbar.tick_params(labelsize=4)  # Tiny tick labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nInterestingly, a large number of states have very weak gun policy strength scores, which is somewhat surprising given the public health risks associated with firearm mortality. This suggests a potential disconnect between the severity of firearm-related outcomes and the strength of preventive legislation in many regions.\n\n\n2 Motivation and Case Studies\nGun violence remains a critical public health issue in the U.S., with over 48,000 deaths in 2022—a rate of one every 11 minutes. The majority of these deaths are from suicide (55%) and homicide (41%), with additional cases stemming from unintentional injuries and police shootings (Johns Hopkins Center for Gun Violence Solutions, 2023). Over 200 people are treated daily for nonfatal firearm injuries.\nKey Drivers of Gun Violence:\n\nFirearm Ownership: The U.S. holds 46% of the world’s civilian guns. States with higher gun ownership consistently report higher firearm mortality (Johns Hopkins Center for Gun Violence Solutions, 2023).\nGeographic Disparities: Gun deaths are concentrated in the South and Mountain West, where gun laws are weaker, and are lowest in the Northeast, where regulations are stricter (Johns Hopkins Center for Gun Violence Solutions, 2023).\nPolicy Gaps: Lax laws on public carry, firearm storage, and background checks correlate with more homicides, child shootings, and police-involved deaths (Johns Hopkins Center for Gun Violence Solutions, 2023).\n\nGun Safety Laws: Impact and Patterns\n\nStates with stronger gun safety laws have gun death rates less than half of those with the weakest laws (Everytown for Gun Safety Support Fund, 2025).\nWeaker law states face significantly higher firearm mortality, often exacerbated by interstate gun trafficking from lenient states—a phenomenon seen in Illinois and Maryland (Everytown for Gun Safety Support Fund, 2025).\nThe “iron pipeline” continues to funnel guns from states without background checks into more regulated regions, undermining local safety efforts (Everytown for Gun Safety Support Fund, 2025).\n\nConclusion\nGun policy strength is a critical factor in reducing firearm violence. States with stronger legislation—especially around storage, background checks, and public carry—see lower mortality rates, while weaker states face higher rates and spillover effects into neighboring regions.\n\n\n3 Research Questions\nData Science Question: How do social, economic, and policy-related factors influence firearm mortality rates across U.S. states?\nSubquestions:\n\nContinuous Predictors (Linear Regression):\n\n\nTo what extent do continuous variables—such as incarceration rate, teen birth rate, and education attainment—predict variation in state-level firearm mortality?\nAre certain socioeconomic indicators (e.g., poverty, unemployment, alcohol-related death rates) more strongly associated with higher firearm mortality?\n\n\nBinary Predictors (Logistic Regression):\n\nHow do the presence or absence of specific gun control policies (e.g., assault weapon bans, background checks, domestic violence restrictions) relate to the likelihood of a state falling into a high vs. low mortality category?\nWhich policies appear most protective when controlling for other state-level characteristics?\n\nModeling Approach:\n\nHow do different linear regression models compare with eachother in terms of performance?\nHow do different logistic regression models compare with eachother in terms of performance?\n\n\n\n\n4 References\n\n\nCenters for Disease Control and Prevention. (2015). NCHS - u.s. And state trends on teen births. https://data.cdc.gov/NCHS/NCHS-U-S-and-State-Trends-on-Teen-Births/y268-sna3/about_data\n\n\nCenters for Disease Control and Prevention. (2022). Stats of the states - firearm mortality. https://www.cdc.gov/nchs/pressroom/sosmap/firearm_mortality/firearm.htm\n\n\nCenters for Disease Control and Prevention. (2024). Suicide prevention funding. https://www.cdc.gov/injury/budget-funding/suicide-prevention-funding.html\n\n\nDataPandas. (2024). Domestic violence by state 2024. https://www.datapandas.org/ranking/domestic-violence-by-state\n\n\nDomesticShelters.org. (n.d.). Domestic violence spending by state. https://www.domesticshelters.org/data-center/state-reports-and-rankings/domestic-violence-spending-per-capita-by-state\n\n\nEverytown for Gun Safety Support Fund. (2025). Gun law rankings: Gun safety laws save lives. https://everytownresearch.org/rankings/\n\n\nEverytown Research & Policy. (n.d.a). Prohibition for convicted domestic abusers. https://everytownresearch.org/rankings/law/prohibition-for-convicted-domestic-abusers/\n\n\nEverytown Research & Policy. (n.d.b). Prohibition for domestic abusers under restraining orders. https://everytownresearch.org/rankings/law/prohibition-for-domestic-abusers-under-restraining-orders/\n\n\nEverytown Research & Policy. (n.d.c). Relinquishment for convicted domestic abusers. https://everytownresearch.org/rankings/law/relinquishment-for-convicted-domestic-abusers/\n\n\nEverytown Research & Policy. (n.d.d). Stalker prohibitor. https://everytownresearch.org/rankings/law/stalker-prohibitor/\n\n\nGowder, C. (2024). Useful stats: Income inequality across the states. https://ssti.org/blog/useful-stats-income-inequality-across-states\n\n\nJohns Hopkins Center for Gun Violence Solutions. (2023). Gun violence in the united states. https://publichealth.jhu.edu/center-for-gun-violence-solutions/research-reports/gun-violence-in-the-united-states\n\n\nK-12 School Shooting Database. (2023). K-12 school shooting database. https://k12ssdb.org/data-visualizations\n\n\nMcGough, M., Amin, K., Panchal, N., & Cox, C. (2023). Child and teen firearm mortality in the u.s. And peer countries. https://www.kff.org/mental-health/issue-brief/child-and-teen-firearm-mortality-in-the-u-s-and-peer-countries/\n\n\nMental Health America. (2022). Ranking the states 2022. https://mhanational.org/issues/2022/ranking-states#prevalence_mi\n\n\nNational Center for Education Statistics. (2019). Selected statistics from the public elementary and secondary education universe: School year 2015–16. https://nces.ed.gov/pubs2018/2018052/tables/table_02.asp\n\n\nNational Center for Education Statistics. (n.d.a). Common core of data (CCD). https://nces.ed.gov/ccd/pubschuniv.asp\n\n\nNational Center for Education Statistics. (n.d.b). Private school universe survey (PSS). https://nces.ed.gov/surveys/PSS/tables/TABLE15fl1920.asp\n\n\nSaunders, H. (2022). Do states with easier access to guns have more suicide deaths by firearm? https://www.kff.org/mental-health/issue-brief/do-states-with-easier-access-to-guns-have-more-suicide-deaths-by-firearm/\n\n\nTreatment Advocacy Center. (2023). Grading the states. https://www.tac.org/wp-content/uploads/2023/11/Grading-the-States-2020.pdf\n\n\nU.S. Bureau of Labor Statistics. (2023). Labor force participation rate for women highest in the district of columbia in 2022. https://www.bls.gov/opub/ted/2023/labor-force-participation-rate-for-women-highest-in-the-district-of-columbia-in-2022.htm\n\n\nU.S. Bureau of Labor Statistics. (2024). Unemployment rates for states. https://www.bls.gov/web/laus/laumstrk.htm\n\n\nUS Census Bureau. (2024). Historical poverty tables: People and families - 1959 to 2023. https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-poverty-people.html\n\n\nWomen in the States. (2013). Highest level of educational attainment of women and men by state, 2013. https://statusofwomendata.org/explore-the-data/poverty-opportunity/additional-state-data/highest-level-of-educational-attainment-of-women-and-men-by-state-2013/\n\n\nWorld Population Review. (2021). Crime rate by state 2020. https://worldpopulationreview.com/state-rankings/crime-rate-by-state\n\n\nWorld Population Review. (2025). Incarceration rates by state 2025. https://worldpopulationreview.com/state-rankings/incarceration-rates-by-state"
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Executive Summary\nOverview of the project examining firearm mortality across U.S. states, key research questions about socioeconomic and policy predictors, data sources, and why a multidimensional approach to understanding gun violence prevention matters.\nExploratory Data Analysis\nDetailed examination of patterns in state-level firearm mortality data.\nLogistic Regression\nComparison of three different logistic regression models (Standard, Lasso/L1, and Ridge/L2) to predict whether states have above-median firearm mortality rates, evaluation of model performance metrics, and analysis of which policy domains most strongly predict mortality outcomes.\nLinear Regression\nComparison of three regression approaches (Principal Component Regression, Backward Stepwise Regression, and Hierarchical Regression) to quantify relationships between socioeconomic factors, gun policies, and firearm mortality rates, with cross-validation to assess generalizability.\nLLM Log\nDocumentation of how large language models were used throughout the project to assist with analysis planning, code development, interpretation of statistical results"
  },
  {
    "objectID": "appendix.html#project-sections",
    "href": "appendix.html#project-sections",
    "title": "Appendix",
    "section": "",
    "text": "Executive Summary\nOverview of the project examining firearm mortality across U.S. states, key research questions about socioeconomic and policy predictors, data sources, and why a multidimensional approach to understanding gun violence prevention matters.\nExploratory Data Analysis\nDetailed examination of patterns in state-level firearm mortality data.\nLogistic Regression\nComparison of three different logistic regression models (Standard, Lasso/L1, and Ridge/L2) to predict whether states have above-median firearm mortality rates, evaluation of model performance metrics, and analysis of which policy domains most strongly predict mortality outcomes.\nLinear Regression\nComparison of three regression approaches (Principal Component Regression, Backward Stepwise Regression, and Hierarchical Regression) to quantify relationships between socioeconomic factors, gun policies, and firearm mortality rates, with cross-validation to assess generalizability.\nLLM Log\nDocumentation of how large language models were used throughout the project to assist with analysis planning, code development, interpretation of statistical results"
  }
]